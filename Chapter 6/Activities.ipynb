{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "patient_data=pd.read_csv(\"Health_Data.csv\")\n",
    "#use the head fucntion to get a glimpse data\n",
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Numerical Data\n",
    "(patient_data.describe())\n",
    "\n",
    "#Summary of Categotical Data\n",
    "patient_data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of Categotical Data\n",
    "patient_data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Numerical Data\n",
    "(patient_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate independent and dependent variables\n",
    "mydata=pd.read_csv(\"Health_Data.csv\")\n",
    "X=mydata.iloc[:,1:9]\n",
    "y=mydata.iloc[:,9]\n",
    "\n",
    "#Datatye of independent and dependent variable\n",
    "print(\"X is:\",type(X))\n",
    "print(\"y is:\",type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X is:\",type(X))\n",
    "print(\"y is:\",type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Admission type\n",
    "A_type=pd.get_dummies(X.iloc[:,1],drop_first=True,prefix='Atype')\n",
    "\n",
    "# New Gender  \n",
    "New_gender=pd.get_dummies(X.iloc[:,4],drop_first=True,prefix='Gender')\n",
    "\n",
    "# New Pre Existing Disease Variable\n",
    "Pre_exdis=pd.get_dummies(X.iloc[:,2],drop_first=True,prefix='PreExistDis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the Original columns\n",
    "X.drop(['Admission_type','PreExistingDisease','Gender'],axis=1,inplace=True)\n",
    "\n",
    "# Concat the new transformed data to X dataframe\n",
    "X=pd.concat([X,A_type,New_gender,Pre_exdis],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Train Test Data & Scaling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split The Data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(X, y, test_size=0.30, random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the inputs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtrain=pd.DataFrame(xtrain,columns=xtest.columns)\n",
    "\n",
    "xtest=sc.transform(xtest)\n",
    "xtest=pd.DataFrame(xtest,columns=xtrain.columns)\n",
    "\n",
    "# Create new objects to store the values as Numpy arrays\n",
    "x_train=xtrain.values\n",
    "x_test=xtest.values\n",
    "y_train=ytrain.values\n",
    "y_test=ytest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=xtrain.values\n",
    "x_test=xtest.values\n",
    "y_train=ytrain.values\n",
    "y_test=ytest.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Arificial Neural Network & Training it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initiate the Model with Sequestial Class\n",
    "model=Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 1st dense layer and Dropout Layer\n",
    "model.add(Dense(units=6,activation='relu',kernel_initializer='uniform',input_dim=11))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "#Add the 2nd dense Layer and Dropout Layer\n",
    "model.add(Dense(units=6,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# Add Output Dense Layer\n",
    "model.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complie the Network\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Fit the Model\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 prediction variables y_pred_class and y_pred_prob\n",
    "# y_pred_class is the predcition & y_pred_prob is probabilities of the prediction\n",
    "y_pred_class=model.predict(x_test)\n",
    "y_pred_prob=model.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Null Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set threshold for 0 and 1. all values above threshold are 1 and below 0 \n",
    "y_pred_class=y_pred_class>0.5\n",
    "\n",
    "\n",
    "# false mean 0 and true mean 1\n",
    "print(y_pred_class[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class.astype(int)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score using ScikitLearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Panda Series value_count function to calculate distinct class values \n",
    "ytest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use head function and divide it by lenght of ytest\n",
    "ytest.value_counts().head(1)/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().head(1)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Always remember that the original values (y_test) should be passed as 1st parameter and y_pred as 2nd\n",
    "cm=confusion_matrix(y_test,y_pred_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity, Specificity, Precision & FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True Negative\n",
    "TN=cm[0,0]\n",
    "\n",
    "#False Negative\n",
    "FN=cm[1,0]\n",
    "\n",
    "#False Positives\n",
    "FP=cm[0,1]\n",
    "\n",
    "#True Positives\n",
    "TP=cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Calculating Sensitivity\n",
    "Sensitivity=TP/(TP+FN)\n",
    "Sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Sensitivity with inbuild function\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test,y_pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Specificity\n",
    "Specificity=TN/(TN+FP)\n",
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "Precision= TP/(TP+FP)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate False Positive_rate\n",
    "Positive_rate= FP/(FP+TN)\n",
    "Positive_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with ROC, AUC & Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#histogram of class distribution\n",
    "plt.hist(y_pred_prob)\n",
    "plt.title(\"Histogram of Predicted Probabilites\")\n",
    "plt.xlabel(\"Predicted Probabilities of patient readmisson\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(fpr,tpr)\n",
    "plt.title(\"ROC Curve for Patient Readmission\")\n",
    "plt.xlabel(\"False Positive rate\")\n",
    "plt.ylabel(\"True Positive rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr,tpr)\n",
    "plt.title(\"ROC Curve for Patient Readmission\")\n",
    "plt.xlabel(\"False Positive rate (1-Specificity)\")\n",
    "plt.ylabel(\"True Positive rate (Sensitivity)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimum_threshold(my_threshold):\n",
    "    print (\"Sensitivity:\",tpr[thresholds>my_threshold][-1])\n",
    "    print (\"Specificity:\",1-fpr[thresholds>my_threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_threshold(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_threshold(0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auc Score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
